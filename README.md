# Brain-Computer-Interface-Music-Generation

This is code from an ongoing multi-disciplinary collaborative project through Georgia Tech.

I am working with the following people:

Professor - Dr. Francesco Fedele https://ce.gatech.edu/node/511

Music Technologist - Dr. Mike Winters https://mikewinters.io/about-me/

Artist - Rachel Grant https://www.rachelgrantstudio.com/

Dancer - Nadya Zeitlin https://www.nadyazeitlin.com/


We are innovating new ways to integrate science and art by using a consumer-grade EEG (Muse https://choosemuse.com/) to convert a person's brainwaves into music.

My role is to convert the raw brainwave data from the Muse into music.

Variations of this include reading Professor Fedele's brainwaves as he writes equations or Rachel's brainwaves as she draws a painting. Nadya then dances to the music generated by these brainwaves.

During performance, I set-up the signal flow as such: the signal from Muse is connected by Bluetooth to one's personal device. This signal is ported into Supercollider through the local network. Supercollider is an audio synthesis platform on which I wrote the code to translate the signal into music. This signal is then sent through a MIDI-bus to Ableton which generates selected soundscapes.

This is a fun project, and we are curious and excited to see how it keeps evolving!
